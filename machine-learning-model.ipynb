{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5337,"sourceType":"datasetVersion","datasetId":3258},{"sourceId":2632847,"sourceType":"datasetVersion","datasetId":1589971}],"dockerImageVersionId":30214,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math  # mathematical functions\nimport cv2  # OpenCV for image processing\nimport matplotlib.pyplot as plt  # data visualization\n\n# TensorFlow and Keras for building and training neural networks\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator  # for image augmentation\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\n# Sklearn for data processing and evaluation\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedKFold, cross_val_score\nfrom sklearn.metrics import f1_score, classification_report\nfrom sklearn.datasets import make_classification\nfrom sklearn.utils import class_weight\n\n# Keras for loading models\nfrom keras.models import load_model\n\nimport pickle\n\ndef load_data(file_path):\n    \"\"\"\n    Load training data from a CSV file.\n\n    Args:\n        file_path (str): The file path to the CSV file.\n\n    Returns:\n        pd.DataFrame: The loaded training data.\n    \"\"\"\n    return pd.read_csv(file_path)\n\ndef preprocess_data(data):\n    \"\"\"\n    Preprocess the data by normalizing inputs and encoding targets.\n\n    Args:\n        data (pd.DataFrame): The training data.\n\n    Returns:\n        tuple: Normalized inputs and encoded targets.\n    \"\"\"\n    targets = data['label']\n    inputs = data.drop(['label'], axis=1)\n    inputs = np.array(inputs)\n    inputs = np.reshape(inputs, (inputs.shape[0], 28, 28, 1))\n    inputs = inputs / 255.0\n    targets = to_categorical(targets)\n    return inputs, targets\n\ndef create_data_generator():\n    \"\"\"\n    Create an ImageDataGenerator for data augmentation.\n\n    Returns:\n        ImageDataGenerator: The data generator for image augmentation.\n    \"\"\"\n    return ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, \n                               height_shift_range=0.1, shear_range=0.1, horizontal_flip=True)\n\ndef step_decay(epoch):\n    \"\"\"\n    Define a step decay learning rate schedule.\n\n    Args:\n        epoch (int): The current epoch number.\n\n    Returns:\n        float: The updated learning rate.\n    \"\"\"\n    initial_lrate = 0.1\n    drop = 0.5\n    epochs_drop = 10.0\n    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n    return lrate\n\ndef my_model():\n    \"\"\"\n    Build and compile the CNN model.\n\n    Returns:\n        Sequential: The compiled Keras Sequential model.\n    \"\"\"\n    classifier = Sequential()\n    classifier.add(Conv2D(1024, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu'))\n    classifier.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    classifier.add(BatchNormalization())\n    classifier.add(Conv2D(512, (5, 5), padding='same', activation='relu'))\n    classifier.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    classifier.add(BatchNormalization())\n    classifier.add(Conv2D(256, (7, 7), padding='same', activation='relu'))\n    classifier.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    classifier.add(BatchNormalization())\n    classifier.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n    classifier.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    classifier.add(BatchNormalization())\n    classifier.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n    classifier.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    classifier.add(BatchNormalization())\n    classifier.add(Flatten())\n    classifier.add(Dense(units=1024, activation='relu'))\n    classifier.add(Dropout(0.2))\n    classifier.add(BatchNormalization())\n    classifier.add(Dense(units=512, activation='relu'))\n    classifier.add(Dropout(0.2))\n    classifier.add(BatchNormalization())\n    classifier.add(Dense(units=256, activation='relu'))\n    classifier.add(Dropout(0.2))\n    classifier.add(BatchNormalization())\n    classifier.add(Dense(units=25, activation=\"softmax\"))\n    classifier.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=0.0, nesterov=False),\n                       loss='categorical_crossentropy',\n                       metrics=['accuracy'])\n    return classifier\n\ndef train_model(model, x_train, y_train, x_test, y_test, batch_size=32, epochs=20):\n    \"\"\"\n    Train the model using k-fold cross-validation.\n\n    Args:\n        model (Sequential): The Keras model to train.\n        x_train (np.ndarray): The training input data.\n        y_train (np.ndarray): The training target data.\n        x_test (np.ndarray): The testing input data.\n        y_test (np.ndarray): The testing target data.\n        batch_size (int): The batch size for training.\n        epochs (int): The number of epochs for training.\n\n    Returns:\n        float: The mean accuracy from cross-validation.\n    \"\"\"\n    training_data_array = np.array(x_train)\n    labels_array = np.array(y_train)\n    kfold = RepeatedKFold(n_splits=5, n_repeats=1)\n    cvscores = []\n\n    for train_index, test_index in kfold.split(training_data_array, labels_array.argmax(1)):\n        x_train_fold, x_test_fold = training_data_array[train_index], training_data_array[test_index]\n        y_train_fold, y_test_fold = labels_array[train_index], labels_array[test_index]\n        data_gen = create_data_generator()\n        train_generator = data_gen.flow(x_train_fold, y_train_fold)\n\n        class_weights = class_weight.compute_class_weight(class_weight=\"balanced\",\n                                                          classes=np.unique(y_train_fold.argmax(1)),\n                                                          y=y_train_fold.argmax(1))\n        class_weights = dict(enumerate(class_weights))\n\n        lrate = LearningRateScheduler(step_decay)\n        model.fit(x_train_fold, y_train_fold, batch_size=batch_size, epochs=epochs, verbose=1,\n                  validation_data=(x_test_fold, y_test_fold))\n        scores = model.evaluate(x_test_fold, y_test_fold, verbose=0)\n        cvscores.append(scores[1] * 100)\n\n    return np.mean(cvscores), np.std(cvscores)\n\ndef save_model(model, file_name):\n    \"\"\"\n    Save the trained model to a file.\n\n    Args:\n        model (Sequential): The Keras model to save.\n        file_name (str): The file name to save the model.\n    \"\"\"\n    model.save(file_name)\n\ndef load_trained_model(file_name):\n    \"\"\"\n    Load a trained Keras model from a file.\n\n    Args:\n        file_name (str): The file name to load the model from.\n\n    Returns:\n        Sequential: The loaded Keras model.\n    \"\"\"\n    return load_model(file_name)\n\ndef main():\n    # Load data\n    train_data = load_data('../input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')\n    inputs, targets = preprocess_data(train_data)\n\n    # Split data\n    x_train, x_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.1, random_state=0)\n\n    # Create and train model\n    model = my_model()\n    mean_accuracy, std_accuracy = train_model(model, inputs, targets, x_test, y_test)\n\n    # Save model\n    save_model(model, \"sign-language-mnist.h5\")\n\n    # Print model summary and accuracy\n    print(\"Model accuracy: %.2f%% (+/- %.2f%%)\" % (mean_accuracy, std_accuracy))\n    loaded_model = load_trained_model(\"sign-language-mnist.h5\")\n    print(loaded_model.summary())\n\nif __name__ == \"__main__\":\n    main()\n\n    # Save the necessary variables and model using pickle\n    with open('model_data.pkl', 'wb') as f:\n        pickle.dump((inputs, targets), f)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:13:05.107389Z","iopub.execute_input":"2024-10-24T18:13:05.108131Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/20\n687/687 [==============================] - 32s 42ms/step - loss: 1.6426 - accuracy: 0.4847 - val_loss: 0.5931 - val_accuracy: 0.7924\nEpoch 2/20\n687/687 [==============================] - 28s 40ms/step - loss: 0.3320 - accuracy: 0.8892 - val_loss: 0.1110 - val_accuracy: 0.9650\nEpoch 3/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.1013 - accuracy: 0.9680 - val_loss: 0.0264 - val_accuracy: 0.9925\nEpoch 4/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0012 - val_accuracy: 1.0000\nEpoch 5/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 0.0064 - val_accuracy: 0.9978\nEpoch 6/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0015 - val_accuracy: 0.9995\nEpoch 7/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 1.2206e-04 - val_accuracy: 1.0000\nEpoch 8/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 7.4130e-04 - val_accuracy: 0.9998\nEpoch 9/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0072 - val_accuracy: 0.9989\nEpoch 10/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 1.2026e-04 - val_accuracy: 1.0000\nEpoch 11/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 6.4715e-05 - val_accuracy: 1.0000\nEpoch 12/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 1.0335e-04 - val_accuracy: 1.0000\nEpoch 13/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 1.6249e-05 - val_accuracy: 1.0000\nEpoch 14/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 9.2546e-06 - val_accuracy: 1.0000\nEpoch 15/20\n687/687 [==============================] - 27s 40ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 8.2359e-06 - val_accuracy: 1.0000\nEpoch 16/20\n503/687 [====================>.........] - ETA: 6s - loss: 0.0023 - accuracy: 0.9994","output_type":"stream"}]}]}